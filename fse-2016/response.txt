Reviewer 1:

Our connection to software engineering is via testing. We are
interested in improving property-based testing (e.g. fuzzing, as you
say), and especially focused on making smarter generators (that don't
necessarily use randomness) so that software engineers can benefit
from push-button techniques.

The supplementary material is here:

 http://www.eecs.northwestern.edu/~robby/tmp/fse2016/

Our evaluation shows that our approach is significantly better than
fuzz testing on short timescales (imagine running in the background of
an IDE while you develop the code).

Thank you for your presentation comments; they will be helpful as we
improve our write up.

Reviewer 2:

We aim to more quickly find bugs in the spirit of fuzz testing, but
without using a source of randomness. We start with a property of the
system that holds for all inputs. The programmer supplies this (a
commonly used one is "for all inputs, this function doesn't
crash"). We then generate inputs to test the property.

Reviewer 3:

The difficulty with fairness (and why it took us 2 years to work out
the formal definition of it) is that the intuitive notion is hard to
pin down in a formal setting without being complex and subtle. We
attempted to compensate for this problem with an informal discussion
in the paper to try to bring across our informal intuition and Coq
proofs to make sure we didn't mess up the complex parts.

We have not yet worked out a notion of fairness for anything with
finiteness. Combining a finite and infinite enumeration seems like it
should be possible in the spirit of the current definition, tho (with
some additional complexity). This is an interesting thought, thank
you.

The bug corpus was built as part of one of the author team's
dissertation (otherwise separately from this work) and is described
with much more care here:
  http://docs.racket-lang.org/redex/benchmark.html.
Short version: the corpus has many bugs that were from real users of
Redex making bugs (not the authors here) and also bugs that we
(experts in Redex) believe are characteristic of common kinds of bugs,
based on our own bug-making experience and helping others on mailing
lists and at the Redex workshop.

Our guess about the crossover is that the random generator has more
diversity in larger terms and the enumeration-based generator, after
an initial productive exploration of small terms, gets bogged down
with very similar terms as the scope gets larger. It would be
interesting to study this question more deeply, we agree; thank you
for suggesting it. That said, this paper is focused on enumerations
and fairness and the comparison of fair and unfair combinators. As
Kuraj, Kuncak, and Jackson (OOPSLA 2015) show, the mildly unfair
combinators are already quite good. Compared to that baseline, our
evaluation shows that fair combinators are a significant
improvement. (We included the random testing baseline since we know it
to be good (in an absolute sense) on Redex programs in the wild.)

Re figure 6: this is generated by randomly picking a (potentially very
large) natural number and using it to index into the enumeration (more
details on this process are at the top of the left column on page 8).

Thank you for your presentation comments. We will certainly
incorporate them in any future version we prepare.
