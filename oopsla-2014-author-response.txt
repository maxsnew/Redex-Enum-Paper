Thanks to all the reviewers for their helpful feedback. We plan to
incorporate all of it in any future version of this paper; things we
don't mention specifically below, we plan to simply follow the
suggestions given (especially with respect to related work).

As for the introduction, we plan to rewrite it. The feedback here is
quite helpful to us in understanding how to rewrite it. In particular,
reviewer A's point that random testing is often combined with feedback
is an especially potent counter-argument to our portrayal and we'll
use that observation as a starting point for re-thinking the
introduction.

Along these lines, we'll also provide some background on Redex. If the
reviewer is curious, our paper "Run Your Research" (POPL 2012) gives
much more background and we'll probably have a high-level version of
that kind of an introduction.

The realism of the benchmark left some reviewers dissatisfied. We
agree that this could be better, but it is not as bad as some seemed
to think. We will clarify this in the paper, but for the record, all
of the benchmark programs (except red-black trees) are "real" Redex
programs in that they match typical things Redex programs do and have
a size of a typical Redex program. RVM is one of the largest Redex
models in existence; list-machine and delim-cont are models published
by others. Several of the bugs there are real bugs, extracted from git
histories. Since the submission date we have also added a model with
let-polymorphism and the classic bug that confounded PL researchers
for about a decade, as well as 8 other real bugs that came up during
the development of that model. We have also identified two bugs based
on the version control history of the R6RS formal model that we expect
to include in the benchmark. (None of these additions change our
overall results.)

Reviewer D points us to Runeson & H\"{o}st: we plan to study this work
more but for now we can certainly say that we'll exise the one
occurrence of "case study" from the paper. If there are other specific
terminological errors that you can point us to, we'll gladly change
our paper. Fundamentally our goal is to communicate effectively what
we've done and using the right terminology helps us with that, so
thank you!

Fairness: we have struggled to find a mathematically precise notion of
fairness. Intuitively, the idea is that a combinator that builds an
enumeration out of sub-enumerations should not look much much deeper
into one enumeration than the others. Pinning this down has proven to
be more difficult that one might think at first glance, but we will
certainly provide more examples and intution than is in the
submission.
